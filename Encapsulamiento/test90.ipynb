{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdbd9a30-46e1-460d-aa08-0714094aa2e6",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0701f0b5-2c50-48ad-a6e5-fd633e6f9cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.18.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.18.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "# Data visualization\n",
    "import cufflinks as cf\n",
    "cf.set_config_file(theme=\"white\", offline=True)\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec184a83-ffe7-4a79-a594-1856ad9b4679",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dcc2cf-b317-4ed6-bbe1-9239c3419030",
   "metadata": {},
   "source": [
    "### Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b7e0d5-6338-4ca2-8a55-9c942963826b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "\n",
    "class Get_Data():\n",
    "    def __init__(self, df= pd.DataFrame()):\n",
    "        self.df= df\n",
    "    \n",
    "    def create_df(self):\n",
    "        \n",
    "        client = Socrata(\"data.lacity.org\", None)\n",
    "        results = client.get(\"2nrs-mtv8\", limit=800000)\n",
    "        results_df = pd.DataFrame.from_records(results)\n",
    "        results_df.to_csv(r'lapd.csv')\n",
    "        self.df = results_df\n",
    "    \n",
    "    \n",
    "    def create_df_n_days(self,n):\n",
    "        client = Socrata(\"data.lacity.org\", None)\n",
    "        # filtro para traer los ultimos n días\n",
    "        date_filter = (datetime.utcnow() - timedelta(days=n)).strftime(\"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "        results = client.get(\"2nrs-mtv8\", where=f\"date_rptd >= '{date_filter}'\", limit=800000)\n",
    "        results_df = pd.DataFrame.from_records(results)\n",
    "        results_df.to_csv(r'lapd_'+str(n)+'_days.csv', index=False)\n",
    "        self.df = results_df       \n",
    "\n",
    "        \n",
    "    def infer_dtypes(self):\n",
    "        ls_dates=[\"date_rptd\", \"date_occ\"]\n",
    "        ls_numeric=[\"vict_age\",\"lat\", \"lon\"]\n",
    "        ls_strings=[x for x in self.df.columns if x not in ls_dates+ls_numeric]\n",
    "        for date in ls_dates:\n",
    "            self.df[date]= pd.to_datetime(self.df[date])\n",
    "        for num in ls_numeric:\n",
    "            self.df[num]= pd.to_numeric(self.df[num])\n",
    "        for s in ls_strings:\n",
    "            self.df[s].apply(lambda x: str(x).split(','))\n",
    "        self.df[\"time_occ\"]=self.df[\"time_occ\"].apply(lambda x: int(x[0:2])*60+int(x[2:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c8e350-9104-4bfe-848b-04e9f2043490",
   "metadata": {},
   "source": [
    "### Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b0f113-713f-4b90-a9d4-c5414194785c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_excel, read_csv\n",
    "from numpy import nan\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "\n",
    "class ProductionCleaner():\n",
    "\n",
    "    def __init__(self,data):\n",
    "        self.df=data.copy()\n",
    "\n",
    "        \n",
    "    def manageNan(self):\n",
    "        # fill nan's and typos\n",
    "        #self.df.loc[self.df.vict_age==0,'vict_age']=nan\n",
    "        #self.df.loc[(self.df.vict_age<0)|(self.df.vict_age>100),'vict_age']=nan\n",
    "        self.df['weapon_used_cd'].fillna('0',inplace=True)\n",
    "        #self.df[\"premis_cd\"].fillna('746',inplace=True)\n",
    "        self.df.loc[self.df.vict_sex.isna(),'vict_sex']='X'\n",
    "        self.df.loc[self.df.vict_sex=='H','vict_sex']=='X'\n",
    "        self.df.loc[self.df.vict_descent.isna(),'vict_descent']='U'\n",
    "        self.df.loc[self.df.lon==0,['lat','lon']]=nan\n",
    "    \n",
    "    def dropColumns(self):\n",
    "        # Drop columns\n",
    "        self.df.drop(['crm_cd_1','crm_cd_2','crm_cd_3','crm_cd_4','area_name','time_occ',\n",
    "                      'crm_cd_desc','premis_desc','weapon_desc', 'status_desc','area_name',\n",
    "                      'date_occ','area','rpt_dist_no','part_1_2','mocodes', \"vict_age\"],axis=1,inplace=True)\n",
    "        try:\n",
    "            self.df.drop(self.df.loc[self.df.status=='CC'].index,inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def manageLocation(self):\n",
    "        # Delete spaces\n",
    "        self.df.location = self.df.location.str.strip()\n",
    "        self.df.location = self.df.location.apply(lambda x: \"  \".join(x.split()))\n",
    "        self.df.location = self.df.location.str.replace(\" \", \"\")\n",
    "        self.df.location = self.df.location.str.upper()\n",
    "        # Replace with dictonary values\n",
    "        directorio = read_csv('Data/Cleaner/Directorio_Lat_Lon.csv')\n",
    "        directorio.location = directorio.location.str.replace(\" \", \"\")\n",
    "        directorio.location = directorio.location.str.upper()\n",
    "        loc_lat = dict(zip(directorio.location,directorio.lat))\n",
    "        loc_lon = dict(zip(directorio.location,directorio.lon))\n",
    "    \n",
    "        # Verificar si las columnas \"lat\" o \"lon\" tienen valores faltantes\n",
    "        mask = self.df['lat'].isna() | self.df['lon'].isna()\n",
    "        # Verificar si los valores de la columna \"location\" están en las claves del diccionario \"loc_lat\"\n",
    "        not_found = ~self.df.loc[mask, 'location'].isin(loc_lat.keys())\n",
    "        self.df.loc[mask & ~not_found, 'lat'] = self.df.loc[mask & ~not_found, 'location'].map(loc_lat)\n",
    "        self.df.loc[mask & ~not_found, 'lon'] = self.df.loc[mask & ~not_found, 'location'].map(loc_lon)\n",
    "        ## Aqui duda, borramos los que no estan en el diccionario y son nulos o que sugieren?\n",
    "        self.df.drop('location',axis=1,inplace=True)\n",
    "        \n",
    "    def clean(self):\n",
    "        ## Esta funcion ya nos deja los datos sin nulos\n",
    "        self.df.drop('cross_street',axis=1,inplace=True)\n",
    "        self.manageNan()\n",
    "        self.dropColumns()\n",
    "        print(self.df.columns)\n",
    "        self.manageLocation()\n",
    "        \n",
    "    \n",
    "            \n",
    "    def clipping(self):\n",
    "        self.df['lon']=self.df['lon'].clip(-118.7, -118.1)\n",
    "        self.df['lat']=self.df['lat'].clip(33.6, 34.4)\n",
    "        \n",
    "    def lugar(self):\n",
    "        pl=[[[119,120,121,145,146.0,150.0,501.0, 502.0, 504.0,507.0, 508.0, 509.0, 510.0,511,515.0, 516.0,707],['vivienda']],\n",
    "            [[101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 109.0, 110.0,116,117,\n",
    "              124.0, 125.0,128,136.0, 137.0,152,154,158,415,705.0,748.0],['calle']],\n",
    "            [[725.0, 726.0,240.0,732.0,752,753,756.0],['gobierno']],\n",
    "            [[123,142,156,204.0, 213.0],['estacionamiento']],\n",
    "            [[151.0,157.0,238,241,254,302,303,304.0, 305.0,702],['establecimiento']],\n",
    "            [[201.0, 202.0, 203.0,205.0, 206.0,208,209.0, 210.0, 211.0,217.0, 218.0,\n",
    "                                219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0,228,233.0,242,244.0, 245.0,\n",
    "                                247.0, 248.0, 249.0,250.0, 251.0, 252.0,255,401.0, 402.0, 404.0, 405.0,\n",
    "                                406.0, 407.0, 408.0,409.0, 410.0, 411.0, 412.0, 413.0, 414.0,417.0,703,\n",
    "                                148.0,709,301,216\n",
    "                                ],['establecimiento_publico']],\n",
    "            [[207,706.0,733.0,735.0],['nocturno']],\n",
    "            [[503,505,519.0],['hotel']],\n",
    "            [[111.0, 112.0, 113.0, 114.0, 115.0,122,126,212.0, 214.0, 215.0,801.0, 802.0,804,809.0, 810.0,\n",
    "                 811.0, 834.0, 835.0, 836.0, 868.0, 869.0, 870.0, 871.0, 872.0, 873.0,\n",
    "                 874.0, 875.0, 876.0, 877.0, 878.0, 879.0, 880.0, 882.0, 883.0, 884.0,\n",
    "                                885.0, 889.0, 890.0, 891.0, 892.0, 893.0, 894.0, 895.0, 896.0, 897.0,\n",
    "                                898.0, 900.0, 901.0, 902.0, 903.0, 904.0, 905.0, 906.0, 907.0, 908.0,\n",
    "                                909.0, 910.0, 911.0, 912.0, 913.0, 915.0, 916.0, 917.0, 918.0, 919.0,\n",
    "                                920.0, 921.0, 922.0, 931.0, 932.0, 933.0, 934.0, 935.0, 936.0, 937.0,\n",
    "                                940.0, 941.0, 942.0, 943.0, 944.0, 945.0, 946.0, 947.0, 948.0, 949.0,\n",
    "                                950.0, 951.0, 952.0, 953.0, 954.0, 956.0, 957.0, 958.0, 961.0, 962.0,\n",
    "                                963.0, 964.0, 965.0, 966.0, 967.0, 968.0, 969.0, 970.0, 971.0,129,135\n",
    "                               ],['transporte']],\n",
    "            [[138,143,727,140],['escaleras']],\n",
    "            [[139,108,147.0,712.0,713,144,714.0, 715.0, 716.0, 717.0, 718.0,711,734.0, 736.0, 737.0, 738.0, 739.0,\n",
    "                  742.0, 743.0,754,757.0, 758.0],['recreacion']],\n",
    "            [[141,149,155,745.0,107.0,118,506.0,518.0,127],['espacio_abierto']],\n",
    "            [[227.0,234.0, 235.0, 236.0, 237.0,239,246.0,253,403,701.0,719,755],['medico']],\n",
    "            [[229,601,602.0, 603.0, 604.0, 605.0, 606.0, 607.0, 608.0],['financiero']],\n",
    "            [[230.0, 512.0,514,517],['cuidado_personas']],\n",
    "            [[231.0,704.0,720.0, 721.0, 722.0, 723.0,724.0,729],['escuela']],\n",
    "            [[232.0,245.0,513,710,744.0,746.0],['otro']],\n",
    "            [[709.0, 730.0, 731.0,740],['iglesia']],\n",
    "            [[750.0, 751.0],['internet']]]\n",
    "        premis=[]\n",
    "        for secc in pl:\n",
    "            premis+=list(zip(secc[0],secc[1]*len(secc[0])))\n",
    "        premis=dict(premis)\n",
    "        self.df.premis_cd= self.df.premis_cd.astype(\"float\")\n",
    "        self.df['premis']=self.df[\"premis_cd\"].apply(lambda x: premis[x] if x in premis.keys() else \"otro\")\n",
    "    def zonas(self):\n",
    "        clusters=pickle.load(open('models/Cleaner/cluster5.sav','rb'))\n",
    "        self.df['zonas']=clusters.predict(self.df[['lat','lon']])\n",
    "    def categorias(self):\n",
    "        columnas=['weapon_used_cd','premis']\n",
    "        for col in columnas:\n",
    "            with open(\"Data/Cleaner/\"+col+\"_categorias\", \"rb\") as fp:  \n",
    "                lista = pickle.load(fp)\n",
    "            self.df[col]=self.df[col].apply(lambda x: x if x in lista else 'Others')\n",
    "    def simple_imp(self):\n",
    "        with open(\"Data/Cleaner/imputer_mode\", \"rb\") as fp:\n",
    "            imputador= pickle.load(fp)\n",
    "        self.df[['premis_cd','crm_cd','status']]=imputador.transform(self.df[['premis_cd','crm_cd','status']])\n",
    "    def super_clases(self):\n",
    "        temp=read_csv('Data/Cleaner/crcode_Supclass.csv')\n",
    "        #temp.drop('NewCode',axis=1,inplace=True)\n",
    "        self.df.crm_cd= self.df.crm_cd.astype(\"int\")\n",
    "        self.df=self.df.merge(temp, how='left', left_on='crm_cd', right_on='crm_cd')\n",
    "        self.df.drop('crm_cd',axis=1,inplace=True)\n",
    "        self.df.rename(columns = {'Superclass':'crime', 'NewCode': 'crm_cd'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d692e-f66f-4b4b-a2f5-e9f508fefaca",
   "metadata": {},
   "source": [
    "### Cubo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ff2976-c32e-4fab-b127-b8615410161b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pandas import date_range, read_csv, DataFrame, to_datetime\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "\n",
    "class CubeCrimesGenerator():\n",
    "    \n",
    "    def __init__(self,df):\n",
    "        self.df = df.copy()\n",
    "        data= self.df.copy()\n",
    "        data[\"Date\"]=data[\"date_rptd\"]\n",
    "        self.start= str(data[\"Date\"].min())\n",
    "        self.end= str(data[\"Date\"].max())\n",
    "        self.ls_dfs=[]\n",
    "    \n",
    "    def checkDates(self,data,zone,crimeType):\n",
    "        data[\"Date\"]=to_datetime(data[\"date_rptd\"])\n",
    "        date_index = date_range(start=self.start, end=self.end, freq=\"D\")\n",
    "        data = data.set_index(\"Date\").reindex(date_index)\n",
    "        data.drop(columns=[\"date_rptd\"], inplace=True)\n",
    "        field = \"Crimes_Z\"+str(zone)+\"T\"+str(crimeType)\n",
    "        data.rename(columns={0: field}, inplace= True)\n",
    "        data[field]= data[field].fillna(0)\n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def generateDataframes(self):\n",
    "        ls_dfs= []\n",
    "        for zone in range(5):\n",
    "            test = self.df[self.df['zonas']==zone].copy()\n",
    "            for crime in range(100,105):\n",
    "                test2 = test[test['crm_cd']==crime].copy()\n",
    "                temp =test2.groupby('date_rptd').size().copy()\n",
    "                temp= temp.to_frame()\n",
    "                temp= temp.reset_index()\n",
    "                data= self.checkDates(temp,zone,crime)\n",
    "                self.ls_dfs.append(data)\n",
    "                \n",
    "    def generateCube(self):\n",
    "        self.generateDataframes()\n",
    "        df_final= self.ls_dfs[0]\n",
    "\n",
    "        for i in range(1, len(self.ls_dfs)):\n",
    "            column= self.ls_dfs[i].columns[0]\n",
    "            df_final[column]= list(self.ls_dfs[i][column])\n",
    "        #df_final[\"week\"]=df_final.index.to_period('W-SUN').start_time\n",
    "            \n",
    "        return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab8414b-8c66-4022-89c2-3c7e5d1b047c",
   "metadata": {},
   "source": [
    "### Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30034b87-5f5a-4c7b-a615-326996b9669f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame, to_datetime\n",
    "class FeatureEngineering():\n",
    "    \n",
    "    def __init__(self,df):\n",
    "        self.df= df\n",
    "        self.df.rename(columns={'Unnamed: 0': \"date\"}, inplace=True)\n",
    "        self.temp= DataFrame()\n",
    "        \n",
    "        \n",
    "    def createLags(self,column):\n",
    "        temp= self.df[[column]].copy()\n",
    "        for i in range(1,32):\n",
    "            temp[column+\"_\"+str(i)] = temp[column].shift(i)\n",
    "        self.temp=temp\n",
    "        self.temp[\"date\"] =to_datetime(self.df[\"date\"])\n",
    "    \n",
    "    def smoothing(self, column):\n",
    "        for i in range(2,10,1):\n",
    "            j=i/10\n",
    "            fit1 = SimpleExpSmoothing(self.temp[column], initialization_method=\"heuristic\").fit(smoothing_level=j, optimized=False)\n",
    "            lista=fit1.fittedvalues\n",
    "            self.temp['exp'+str(j)]=lista\n",
    "            \n",
    "    def createMA(self,column):\n",
    "        for i in range(10,50,10):\n",
    "            self.temp[\"MA\"+str(i)]= self.temp[column].rolling(window =i).mean()\n",
    "    \n",
    "   \n",
    "    \n",
    "    def createVariables(self,column):\n",
    "        self.createLags(column)\n",
    "        #self.smoothing(column)\n",
    "        self.createMA(column)\n",
    "        self.temp[\"Target\"]= self.temp[column].shift(-10)\n",
    "        self.temp.dropna(inplace=True)\n",
    "        return self.temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e59a6fe-8daf-420e-b02d-6af46a2afc10",
   "metadata": {},
   "source": [
    "### Predicter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d565a8b-967b-409f-b34a-2d13397cbe56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from pandas import to_datetime, DataFrame\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from numpy import sqrt\n",
    "class Predicter():\n",
    "    \n",
    "    def __init__(self,data,column):\n",
    "        self.df = data.copy()\n",
    "        self.column= column\n",
    "        self.zone=column[8]\n",
    "        self.crime=column[10:]\n",
    "        \n",
    "    def loadModel(self):\n",
    "        model_path= \"NewModels/XGBoost/modeloSem_\"+self.zone+\"_\"+self.crime+\".pkl\"\n",
    "        self.model = pickle.load(open(model_path, 'rb'))\n",
    "    \n",
    "    def loadScalers(self):\n",
    "        sx_path= \"NewModels/diario/sc_x_\"+self.zone+\"_\"+self.crime+\".pkl\"\n",
    "        sy_path= \"NewModels/diario/sc_y_\"+self.zone+\"_\"+self.crime+\".pkl\"\n",
    "        \n",
    "        self.scx= pickle.load(open(sx_path, 'rb'))\n",
    "        self.scy=pickle.load(open(sy_path, 'rb'))\n",
    "    \n",
    "    def scaleData(self):\n",
    "        X,y=self.df.drop([\"Target\",'date','y_hat'],axis=1).to_numpy(),self.df[[\"Target\"]].to_numpy()\n",
    "        self.X=self.scx.transform(X)\n",
    "        self.y=self.scy.transform(y)\n",
    "    \n",
    "    def forecast(self):\n",
    "        self.df[\"y_hat\"] = self.scy.inverse_transform(self.model.predict(self.scx.transform(self.df.drop(['date','Target'],axis=1).to_numpy())).reshape(-1,1)).round(0) \n",
    "        \n",
    "    def weekPredictions(self):\n",
    "        df_week= self.df[[\"date\",\"Target\",\"y_hat\"]].copy()\n",
    "        df_week[\"date\"]= to_datetime(df_week[\"date\"]) + timedelta(days=10)\n",
    "        df_week.set_index(\"date\", inplace=True)\n",
    "        df_week[\"week\"]=df_week.index.to_period('W-SUN').start_time\n",
    "        self.df_final= df_week.groupby(by=\"week\").sum()\n",
    "        self.df_final[\"zone\"] = self.zone\n",
    "        self.df_final[\"crime\"]= self.crime\n",
    "        \n",
    "    def getMetrics(self):\n",
    "        y_pred = self.scy.inverse_transform((self.model.predict(self.X)).reshape(-1,1))\n",
    "        rmse = sqrt(mean_squared_error(self.scy.inverse_transform(self.y.reshape(-1,1)), y_pred))\n",
    "        mae= mean_absolute_error(self.scy.inverse_transform(self.y.reshape(-1,1)), y_pred)\n",
    "        self.df_metrics= DataFrame(columns=[\"Zone\",\"Crime\",\"RMSE\",\"MAE\"],\n",
    "                                  data= [(self.zone,self.crime,rmse, mae)],\n",
    "                                  index=range(1))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da90062e-2b8b-486a-8d23-d7a596a864ea",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395dc71f-0347-4989-b91e-92afcd901b67",
   "metadata": {},
   "source": [
    "### Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cde156ce-4bea-4077-bc3c-fd084fabf06b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colecter= Get_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bbf8d16-e8e7-4ac3-834a-1c0b6e0a2b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "aux=colecter.create_df_n_days(90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b5ab1-eef4-417a-96f4-bc750c0e7bd7",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "236f6225-7fff-4d1e-b58c-53d04c21273e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbed4a76-00c3-40df-98c5-3033f715a7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner= ProductionCleaner(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cf0f0ab-e8f7-434c-b942-c8a9ba789031",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['dr_no', 'date_rptd', 'crm_cd', 'vict_sex', 'vict_descent', 'premis_cd',\n",
      "       'weapon_used_cd', 'status', 'location', 'lat', 'lon'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cleaner.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a21805a-ee89-414b-a5b1-81681563a16c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner.clipping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ee3ed0d-52e7-4e4a-ad50-1cf0384f33ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner.simple_imp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69f7a32d-9116-425c-bc38-f7a8d93ccc58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner.lugar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02b07fa2-3b7e-47eb-8bf8-a945cd510276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner.zonas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a05a71e-8b77-4683-9ec3-eaef870425e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner.categorias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53e27e9e-ba93-409a-a2f7-48bb53e1a0d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner.super_clases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b46edbf-f9fe-4b5f-90aa-3c4aa703ce05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner.df.to_csv(\"Test90Days/limpios.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228328a1-b3d6-47fd-9f18-4887c11890cc",
   "metadata": {},
   "source": [
    "### Generate cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae0766-942b-42b5-8246-19b5b4749727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_clean=pd.read_csv(\"Test90Days/limpios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7975de70-2f36-460b-bae1-33796378f78b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cubo= CubeCrimesGenerator(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbaa0c-b8ff-42ff-9834-34f9727dcbef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cubo= cubo.generateCube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ae63d-a324-4fc0-b8ce-b14dd61859bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cubo.to_csv(\"Test90Days/cubo90.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11438abd-c4a0-48c2-beab-4ab28c41f5ec",
   "metadata": {},
   "source": [
    "### Generate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c3a6e-5a5e-4e0d-9d4a-704fc60733a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_cubo= pd.read_csv(\"Test90Days/cubo90.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9736f4a-abb6-4b9b-a127-aeb760285868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature= FeatureEngineering(data_cubo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "189c80a1-5013-4dea-897e-471e879d86f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column=\"Crimes_Z4T100\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43c0d187-81ac-4bb4-b1c6-d405b02dc9d5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_features= feature.createVariables(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "342c1afe-c442-4467-846a-254d68f7c944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_features.to_csv(\"Test90Days/features90.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853c886c-da77-4f3e-9641-ce94f67170b5",
   "metadata": {},
   "source": [
    "### Generate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "623fdf08-0619-44d1-b194-1b752d461bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_feature= pd.read_csv(\"Test90Days/features90.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "64640f9d-b962-41d8-8403-e69d1fb5992a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor= Predicter(data_feature,column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef64495d-5733-42a2-94a5-ac06cde744f9",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "03aca722-ece1-4e59-97da-1a5830603a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.loadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c83bd0-9b28-4bd6-9f7a-4cae85967d87",
   "metadata": {},
   "source": [
    "### Load Scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7fe40b27-e1e6-49c3-98cc-8b52d382bded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.loadScalers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a54cef5-5862-4841-93d7-c9c3e83f026e",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "56b62fcf-13d9-4ee2-bd6f-fb9c91e03758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.forecast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5c79b60c-5092-456d-9dc3-d798cd633ad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.weekPredictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fa9dde53-7e7d-4824-944e-22473c008c99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>y_hat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-27</th>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03</th>\n",
       "      <td>42.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-10</th>\n",
       "      <td>51.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-17</th>\n",
       "      <td>46.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-24</th>\n",
       "      <td>30.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-01</th>\n",
       "      <td>40.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-05-08</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Target  y_hat\n",
       "week                     \n",
       "2023-03-27    20.0   19.0\n",
       "2023-04-03    42.0   50.0\n",
       "2023-04-10    51.0   50.0\n",
       "2023-04-17    46.0   48.0\n",
       "2023-04-24    30.0   48.0\n",
       "2023-05-01    40.0   40.0\n",
       "2023-05-08     4.0    3.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dfee51b0-bc86-498c-8077-8581869054b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.scaleData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "09632159-2301-4992-9619-8654b5631bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.getMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7099d411-814a-4765-812e-11384d6726c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zone</th>\n",
       "      <th>Crime</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>3.358005</td>\n",
       "      <td>2.536643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Zone Crime      RMSE       MAE\n",
       "0    4   100  3.358005  2.536643"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb73dc7-d14f-4fa4-b957-b9ae76473304",
   "metadata": {},
   "source": [
    "## Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57045e7-c187-40a8-a4c4-6f8c0e54bde1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_cubo= pd.read_csv(\"Test90Days/cubo90.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb809093-e1df-415e-9eda-73730a404434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls_predictions=[]\n",
    "ls_metrics= []\n",
    "for zone in range(5):\n",
    "    for crime in range(100,105):\n",
    "        feature= FeatureEngineering(data_cubo)\n",
    "        column=\"Crimes_Z\"+str(zone)+\"T\"+str(crime)\n",
    "        df_features= feature.createVariables(column)\n",
    "        path= \"metrics/features\"+column+\".csv\"\n",
    "        df_features.to_csv(path, index=False)\n",
    "        data_feature= pd.read_csv(path)\n",
    "        predictor= Predicter(data_feature,column)\n",
    "        predictor.loadModel()\n",
    "        predictor.loadScalers()\n",
    "        predictor.forecast()\n",
    "        predictor.weekPredictions()\n",
    "        ls_predictions.append(predictor.df_final)\n",
    "        predictor.scaleData()\n",
    "        predictor.getMetrics()\n",
    "        ls_metrics.append(predictor.df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb1aad-7fdd-46ab-9593-594cf69768e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat(ls_predictions, ignore_index=True).to_csv(\"metrics/predicciones.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12605472-7ae8-4abc-a02a-5dcc8957d728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat(ls_metrics, ignore_index=True).to_csv(\"metrics/metricas.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57868d0-5a67-47d2-b768-815e5e6d61fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlapd",
   "language": "python",
   "name": "vlapd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
